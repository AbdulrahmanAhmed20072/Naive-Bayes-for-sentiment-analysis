{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imqmKRifMUOq",
        "outputId": "9a44a3c5-32f0-48e5-c9a1-26638c18986a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords, twitter_samples\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "from utils_w2 import process_tweet, lookup\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('twitter_samples')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_pos = twitter_samples.strings('positive_tweets.json')\n",
        "all_neg = twitter_samples.strings('negative_tweets.json')\n",
        "\n",
        "train_pos = all_pos[:4000]\n",
        "test_pos = all_pos[4000:]\n",
        "\n",
        "train_neg = all_neg[:4000]\n",
        "test_neg = all_neg[4000:]\n",
        "\n",
        "x_train = train_pos + train_neg\n",
        "x_test = test_pos + test_neg\n",
        "\n",
        "y_train = np.concatenate([np.ones((len(train_pos))) , np.zeros((len(train_neg)))], axis = 0)\n",
        "y_test = np.concatenate([np.ones((len(test_pos))) , np.zeros((len(test_neg)))], axis = 0)"
      ],
      "metadata": {
        "id": "niwN6ZutOI-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_pos), len(test_pos), len(train_neg), len(test_neg), len(y_train), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhxyOnywPjNL",
        "outputId": "b6be2928-5c67-43bc-afeb-74cbc06d4cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000, 1000, 4000, 1000, 8000, 2000)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "custom_tweet = \"RT @Twitter @chapagain Hello There! Have a great day. :) #good #morning http://chapagain.com.np\"\n",
        "\n",
        "process_tweet(custom_tweet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17qm-RVOP_r6",
        "outputId": "a036cc7f-25b1-4a56-e9fa-4572988c4be1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello', 'great', 'day', ':)', 'good', 'morn']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_tweets(tweets, ys, res = {}):\n",
        "\n",
        "  for (tweet, y) in zip(tweets, ys):\n",
        "    for word in process_tweet(tweet):\n",
        "\n",
        "      pair = (word, y)\n",
        "      res[pair] = res.get(pair,0) +1\n",
        "\n",
        "  return res"
      ],
      "metadata": {
        "id": "j2d9AwUIQLe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets = x_train\n",
        "ys = y_train\n",
        "\n",
        "freqs = count_tweets(tweets, ys)"
      ],
      "metadata": {
        "id": "nxABWnkmRmW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(freqs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIWbZE--VVt5",
        "outputId": "96c69480-5ffb-4066-e380-35a33dd2feda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11427"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_naive_bayes(x, y, freqs):\n",
        "\n",
        "  N_pos,N_neg, V_pos,V_neg = 0, 0, 0, 0\n",
        "\n",
        "  for pair in freqs:\n",
        "\n",
        "    # check the word pos or neg, get freq of each word in pos and neg\n",
        "    if pair[1] > 0:\n",
        "      N_pos += freqs[pair]\n",
        "      V_pos += 1\n",
        "\n",
        "    else:\n",
        "      N_neg += freqs[pair]\n",
        "      V_neg += 1\n",
        "\n",
        "  # get total pos and neg words\n",
        "  D_pos = (y == 1).sum()\n",
        "  D_neg = (y == 0).sum()\n",
        "\n",
        "  # calculate prior\n",
        "  logPrior = np.log(D_pos / D_neg)\n",
        "\n",
        "  # get set of all words \"vocab\"\n",
        "  vocab = set([pair[0] for pair in freqs])\n",
        "  V = len(vocab)\n",
        "\n",
        "  logliklyhood = {}\n",
        "\n",
        "  for word in vocab:\n",
        "\n",
        "    # for each word in vocab, het the pos and neg count\n",
        "    freq_pos = lookup(freqs, word, 1)\n",
        "    freq_neg = lookup(freqs, word, 0)\n",
        "\n",
        "    # get proba for for each word in a desired class\n",
        "    p_w_pos = (freq_pos +1) / (N_pos + V)\n",
        "    p_w_neg = (freq_neg +1) / (N_neg + V)\n",
        "\n",
        "    logliklyhood[word] = np.log(p_w_pos / p_w_neg)\n",
        "\n",
        "  return logPrior,logliklyhood"
      ],
      "metadata": {
        "id": "dIqppBVyVw46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logprior, loglikelihood  = train_naive_bayes(x_train, y_train, freqs)"
      ],
      "metadata": {
        "id": "NuupeEztARYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(loglikelihood), logprior"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmrwCW-UAcQT",
        "outputId": "b7f3ddd2-eeb5-4af8-8501-96ced97fa8fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9161, 0.0)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def naive_bayes_predict(tweet, loglikelihood, logprior):\n",
        "\n",
        "  # process tweet\n",
        "  processed = process_tweet(tweet)\n",
        "  proba = logprior\n",
        "\n",
        "  for word in processed:\n",
        "    proba += loglikelihood.get(word,0)\n",
        "\n",
        "  return proba"
      ],
      "metadata": {
        "id": "eufg4wLBuoBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet = 'she smiled.'\n",
        "naive_bayes_predict(tweet,loglikelihood, logprior)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMwHcVKb1bkO",
        "outputId": "ebdaa8c9-8154-442a-d9bb-6fa516e0e4d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.557492820301094"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_naive_bayes(x_test, y_test, loglikelihood, logprior):\n",
        "\n",
        "  pred = []\n",
        "  for tweet in x_test:\n",
        "\n",
        "    y_hat = naive_bayes_predict(tweet, loglikelihood, logprior)\n",
        "    pred.append(1 if y_hat > 0 else 0)\n",
        "\n",
        "  # return accuracy for y_test and pred\n",
        "  return (y_test == pred).sum() / len(pred)"
      ],
      "metadata": {
        "id": "_tCqCapi1lCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = test_naive_bayes(x_test, y_test,loglikelihood, logprior)"
      ],
      "metadata": {
        "id": "NYU8cT3YKi1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " = ['I am happy', 'I am bad',\n",
        "    'this movie should have been great.',\n",
        "    'great', 'great great', 'great great great',\n",
        "    'great great great great']\n",
        "\n",
        "for tweet in test_tweets:\n",
        "\n",
        "  p = naive_bayes_predict(tweet, loglikelihood, logprior)\n",
        "  print(f'{tweet} -> {p:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yr-qxwpBKqz2",
        "outputId": "6fd4b5b5-ea14-4bfc-e1d9-ac73ce271ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am happy -> 2.14\n",
            "I am bad -> -1.31\n",
            "this movie should have been great. -> 2.12\n",
            "great -> 2.13\n",
            "great great -> 4.26\n",
            "great great great -> 6.39\n",
            "great great great great -> 8.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ratio(freqs, word):\n",
        "\n",
        "  pos_neg_ratio = {'positive' : 0, 'negative' : 0, 'ratio' : 0}\n",
        "\n",
        "  pos_neg_ratio['positive'] = lookup(freqs, word, 1)\n",
        "  pos_neg_ratio['negative'] = lookup(freqs, word, 0)\n",
        "\n",
        "  pos_neg_ratio['ratio'] = (lookup(freqs, word, 1) +1) / (lookup(freqs, word, 0) +1)\n",
        "\n",
        "  return pos_neg_ratio"
      ],
      "metadata": {
        "id": "XCb7Ekd7OVyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_ratio(freqs, 'happy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6ndc7EFQJja",
        "outputId": "300be79f-2c21-4868-c522-deae90cc1ecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'positive': 162, 'negative': 18, 'ratio': 8.578947368421053}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_words_by_threshold(freqs, label, threshold):\n",
        "\n",
        " # get most n words in a specific class\n",
        " # ex, get the fifty most positive words\n",
        "  word_list = {}\n",
        "  for pair in freqs.keys():\n",
        "\n",
        "    word,_ = pair\n",
        "    pos_neg_ratio = get_ratio(freqs, word)\n",
        "\n",
        "    if label == 1 and pos_neg_ratio['ratio'] >= threshold:\n",
        "      word_list[word] = pos_neg_ratio\n",
        "\n",
        "    elif label == 0 and pos_neg_ratio['ratio'] <= threshold:\n",
        "      word_list[word] = pos_neg_ratio\n",
        "\n",
        "  return word_list"
      ],
      "metadata": {
        "id": "S-EcB1eFQPtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_words_by_threshold(freqs, 1, 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaBcJ34AV79Q",
        "outputId": "6144e32b-0683-4a42-a499-61ec5c750208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{':)': {'positive': 2960, 'negative': 2, 'ratio': 987.0},\n",
              " ':d': {'positive': 523, 'negative': 0, 'ratio': 524.0},\n",
              " ':p': {'positive': 105, 'negative': 0, 'ratio': 106.0},\n",
              " ':-)': {'positive': 552, 'negative': 0, 'ratio': 553.0},\n",
              " 'stat': {'positive': 51, 'negative': 0, 'ratio': 52.0}}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}